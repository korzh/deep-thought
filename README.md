## Objective

Задача полягає у знаходженні відповідей на питання на основі деякого набору документів. 
На першому етапі правильною відповіддю вважається знаходження вже існуючого документа в базі.

На вхід у нас подається два набори:
 * власне набір текстів документів (відповідей на питання)
 * набір текстів з питаннями де для кожного з питань вказується ID документа що відповідає на це питання.

## Baseline solution

Маємо задачу класифікації. На вхід отримуємо текст, а на виході треба вказати один з документів (класів), що відповідає цьому тексту.
В якості базового рішення був обраний підхід на основі bag of words та TF/IDF.

1. Ініціюємо модель.
Для цього ми послідовно скануємо всі документи і для кожного з них
 * токенізуємо текст.
 * відкидаємо стоп-слова
 * отримаємо стеми для кожного слова розміщуємо їх у BoW з вказанням ваги слова для цього документа.
Вага - це кількість входжень слова (точніше його стема) у документ. Для слів з заголовків вага ще множиться на деякий коефіцієнт.

2. Тренуємо на питаннях
 * Повторюємо процедуру з пункту #1 для всіх питань з нашого набору даних.
 * Підраховуємо коефіцієнти TF/IDF для кожної пари слово - документ.
 
3. Класифікатор 
 * Ініціюємо початковий вектор ваг для кожного документа 0-ми.
 * Робимо токенізацію вхідного тексту, відкидання стоп слів та стемінг.
 * Для кожної стеми рахуємо отримаємо вектор ваг (TF/IDF) за нашої моделі та додаємо його до поточного вектору ваг.
 * Отриманий в кінці вектор сортуємо та беремо перших 3 документа з найбільшою вагою. 
 
Передбачення вважається вдалим якщо потрібний документ (правильна відповідь) був вказаний в одному з 3 варіантів, що ми отримали.



## How to run

Створено консольну програму `deepth` (каталог /ConsoleApp), яка дозволяє вам ініціювати, 
натренувати та протестувати модель та класифікатор на будь-якій базі даних, що складається з деякого набору документів (статей) та питань до них, представлених у форматі XML. У каталозі 
/ConsoleApp/data є приклад такої бази даних: питання та відповіді на StackOverflow, за тематикою .NET.

Щоб запустити програму потрібен [.NET Core run-
time](https://www.microsoft.com/net/download/all) версії 2.0 (або вище)

У каталозі `/ConsoleApp` є .bat файл який послідовно запускає `deepth` 3 рази:
 * з командою `init`, що ініціює нашу модель та тренує ії на документах з файлу data/sofdn-articles.xml
 * з командою `train`, що дотреновує модель на питаннях, записаних у файлі data\sofdn-questions-train.xml 
 * з командою `test`, що тестує побудовану модель на питаннях з файлу data\sofdn-questions-test.xml 


## Results

Результат тестування 2000 тестових питань на моделі, що була навчена на тренувальному сеті з 
5000 документів + 5000 питань показав доволі непоганий результат у precision=0.83. Оцінювати Recall в даному випадку немає сенсу, адже в тестовому сеті не було питань, що не мають відповідей тому TN та FN будь 0-ими у будь-якому випадку. В будь якому разі поточна реалізація 
для цього взагалі не пристосована, адже значення "релевантності" документів що ми отримаємо в кінці не нормалізовані і тому не можна поставити деякий threshold, щоб відсікати документи, які 
не відповідають на питання взагалі. 

Більш детально результати тестового прогону можна подивитись у файлі /ConsoleApp/results.txt


## Problems

 * Поточна реалізація зовсім не пристосована для обробки достатньо великих баз документів/питань. Вже на тестовому прогоні (5000+5000) у нас вийшов словник на майже 13000 
слів (тобто стем), що дає нам в результаті дуже розріджену матрицю у 130 млн комірок, і це дуже сповільнює подальшу обробку. Треба змінювати формат зберігання та обробки.
 
 * Нема нормалізації ваг, як вже було зазначено вище, і тому зараз неможливо "зловити" випадок, коли на питання взагалі немає відповіді.
 
 * Алгоритм досить "тупий" та не враховує ані порядок ані сенс слів у документах. Зараз якщо перебудувати питання, на яке у нас є відповідь, використавши синоніми слів, що входять до питання - то скоріш за все потрібна відповідь (документ) не буде знайдена.
 

## Next steps

Щоб хотілось зробити:

1. Спробувати застосувати векторне представлення слів, щоб дозволило б шукати відповіді за "сенсом" запитання, а не просто за набором слів у ньому.

2. Власне вирішити інші проблеми, вказані вище.

3. Створити механізм автоматичної генерації відповідей замість просто пошуку готових відповідей у базі документів. 
Але, на відміну від попередніх двох кроків - тут я, поки що, зовсім не маю уявлення як це робити.
 
Хоча, у принципі, алгоритм, названий deep thought може просто завжди видавати 42 у відповідь :)



